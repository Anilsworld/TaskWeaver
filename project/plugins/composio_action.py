# -*- coding: utf-8 -*-
"""
Composio Action Plugin for TaskWeaver (Eclipse)
================================================

Execute any Composio action (800+ integrations) from TaskWeaver-generated code.

This plugin follows TaskWeaver's standard plugin pattern and provides access to:
- Gmail (send, read, forward emails)
- Google Sheets (read, write, update)
- Slack (post messages, read channels)
- And 800+ more integrations

Usage in generated code:
    # Execute any Composio action
    result, description = composio_action(
        action_name="GOOGLESHEETS_SPREADSHEETS_VALUES_BATCH_GET",
        params={"spreadsheetId": "1abc...", "ranges": ["Sheet1!A1:B10"]}
    )
"""

import os
import sys
import json
import logging
import re
from typing import Dict, Any, Tuple, Optional, Union, List, Set

from taskweaver.plugin import Plugin, register_plugin, test_plugin

logger = logging.getLogger(__name__)


@register_plugin
class ComposioAction(Plugin):
    """
    TaskWeaver plugin for executing Composio actions.
    
    Provides a simple interface for TaskWeaver-generated code to call
    any of the 800+ Composio integrations (Gmail, Google Sheets, Slack, etc.)
    
    ACTION RESOLUTION (sql_pull_data pattern):
    ------------------------------------------
    TaskWeaver's LLM may generate "conceptual" action names like GMAIL_GET_LAST_EMAILS
    that don't exist in our DB. This plugin follows the sql_pull_data pattern:
    1. Accept approximate action name from TaskWeaver
    2. Resolve to actual action ID using semantic search
    3. Execute the resolved action
    
    SIMULATION MODE:
    ----------------
    When running in TaskWeaver's Docker container (CES), Django services are not
    available. The plugin detects this and returns realistic mock responses so
    TaskWeaver can continue generating code for ALL steps in the plan.
    
    The actual execution happens later via langgraph_adapter using the real
    ComposioService with user's connected accounts.
    """
    
    _composio_service = None
    _action_matcher = None  # Reuse existing semantic search
    _simulation_mode = None  # None = unknown, True = simulation, False = real
    _host_callback_available = None  # Can we call back to Django host?
    _schema_cache = None  # Cached schemas from JSON file (response schemas)
    _resolver_graph = None  # Maps param types to SEARCH/FIND actions that produce them
    _action_metadata_cache = None  # Cached action metadata (parameters_schema, parameter_examples, response_schema)
    
    def _get_schema_cache_path(self) -> str:
        """Get schema cache file path from config (TaskWeaver pattern)."""
        cache_file = self.config.get("schema_cache_path", "composio_schemas_cache.json")
        # Try multiple locations - Docker container path FIRST since __file__ 
        # resolves to temp dir in container
        locations = [
            # 1. Container mounted path (Docker) - CHECK FIRST!
            f"/app/plugins/{cache_file}",
            # 2. Relative to plugin directory (host)
            os.path.join(os.path.dirname(__file__), cache_file),
            # 3. Current working directory
            cache_file,
        ]
        for path in locations:
            if os.path.exists(path):
                print(f"[COMPOSIO_PLUGIN] Found cache at: {path}")
                return path
        print(f"[COMPOSIO_PLUGIN] Cache not found in: {locations}")
        return locations[1]  # Default to host location
    
    def _load_schema_cache(self) -> Dict[str, Any]:
        """Load schema cache from JSON file (for Docker container without Django)."""
        if self._schema_cache is not None:
            return self._schema_cache
        
        cache_path = self._get_schema_cache_path()
        try:
            if os.path.exists(cache_path):
                with open(cache_path, 'r', encoding='utf-8') as f:
                    ComposioAction._schema_cache = json.load(f)
                    print(f"[COMPOSIO_PLUGIN] Loaded {len(self._schema_cache)} schemas from {cache_path}")
                    return self._schema_cache
            else:
                print(f"[COMPOSIO_PLUGIN] Cache file not found: {cache_path}")
        except Exception as e:
            print(f"[COMPOSIO_PLUGIN] Failed to load schema cache: {e}")
        
        ComposioAction._schema_cache = {}
        return self._schema_cache
    
    def _is_simulation_mode(self) -> bool:
        """
        Detect if we're running in simulation mode (Docker CES) vs real execution.
        
        Simulation mode indicators:
        - Django not available
        - ComposioService import fails
        - Running in Docker container
        """
        if self._simulation_mode is not None:
            return self._simulation_mode
        
        try:
            # Try to import Django and check if it's configured
            import django
            os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'config.settings')
            
            # Check if Django apps are ready
            if not django.apps.apps.ready:
                try:
                    django.setup()
                except Exception:
                    self._simulation_mode = True
                    return True
            
            # Try to import ComposioService
            from apps.integrations.services.composio_service import ComposioService
            self._simulation_mode = False
            return False
            
        except (ImportError, Exception) as e:
            logger.info(f"[COMPOSIO_PLUGIN] Simulation mode detected: {e}")
            self._simulation_mode = True
            return True
    
    def _call_host_api(self, action_name: str, params: Dict[str, Any]) -> Optional[Tuple[Dict[str, Any], str]]:
        """
        Call the Django host's internal API to execute the action.
        
        This allows the Docker container to make REAL Composio API calls by
        calling back to the host where Django and credentials are available.
        
        Returns:
            (data, description) tuple if successful, None if callback failed
        """
        # =====================================================================
        # SCALABLE FIX (arch-44): Skip real API during workflow GENERATION
        # =====================================================================
        # During workflow generation, form_collect returns mock data which will
        # cause API validation failures. We should mock ALL API calls during
        # generation - real APIs are only called during workflow EXECUTION.
        #
        # Session variable `_workflow_generation_mode` is set by eclipse_adapter
        # when creating the session.
        # =====================================================================
        is_generation_mode = self.ctx.get_session_var("_workflow_generation_mode", None)
        logger.info(f"[COMPOSIO_PLUGIN] üîç CHECK: _workflow_generation_mode = '{is_generation_mode}' for {action_name}")
        if is_generation_mode == "true":
            logger.info(f"[COMPOSIO_PLUGIN] ‚úÖ GENERATION MODE - returning mock for {action_name}")
            return None  # Triggers mock fallback
        else:
            logger.info(f"[COMPOSIO_PLUGIN] ‚ö†Ô∏è EXECUTION MODE - calling real API for {action_name}")
        
        if self._host_callback_available is False:
            return None
        
        try:
            import requests
            
            # Get session ID from context (set by TaskWeaver)
            session_id = self.ctx.session_id if hasattr(self.ctx, 'session_id') else None
            entity_id = self.ctx.get_session_var("_composio_entity_id", None)
            
            # Host URL - try multiple options for Docker networking
            host_urls = [
                "http://host.docker.internal:8000",  # Docker Desktop (Windows/Mac)
                "http://172.17.0.1:8000",  # Docker Linux bridge
                "http://localhost:8000",  # Local development
            ]
            
            payload = {
                "session_id": session_id,
                "action_name": action_name,
                "params": params,
                "entity_id": entity_id
            }
            
            for host_url in host_urls:
                try:
                    url = f"{host_url}/api/v1/integrations/internal/execute/"
                    logger.info(f"[COMPOSIO_PLUGIN] Trying host callback: {url}")
                    
                    response = requests.post(
                        url,
                        json=payload,
                        timeout=30,
                        headers={"Content-Type": "application/json"}
                    )
                    
                    if response.status_code == 200:
                        result = response.json()
                        self._host_callback_available = True
                        
                        if result.get('success') or result.get('successfull'):
                            data = result.get('data', result)
                            
                            # =========================================================
                            # SCALABLE FIX (arch-35): Dynamic structure hint for LLM
                            # =========================================================
                            # Auto-describe response structure so LLM writes correct
                            # parsing code on FIRST try, not via retry loop.
                            # =========================================================
                            structure_hint = self._describe_data_structure(data)
                            
                            description = (
                                f"Successfully executed {action_name}.\n"
                                f"RESPONSE STRUCTURE: {structure_hint}\n"
                                f"Use the structure above to access the data correctly."
                            )
                            
                            # ‚úÖ CRITICAL: Print description so LLM can see it!
                            print(f"\n{description}\n")
                            
                            logger.info(f"‚úÖ [COMPOSIO_PLUGIN] Host callback succeeded: {action_name}")
                            return data, description
                        else:
                            # =========================================================
                            # CRITICAL FIX (arch-25): RAISE EXCEPTION on API failure!
                            # =========================================================
                            # This enables TaskWeaver's retry loop to self-correct!
                            # The LLM will see the error and fix the parameters.
                            # =========================================================
                            error = result.get('error', 'Unknown error')
                            logger.error(f"‚ùå [COMPOSIO_PLUGIN] API FAILURE (will trigger retry): {error}")
                            
                            raise RuntimeError(
                                f"Composio API error for {action_name}: {error}\n"
                                f"Parameters provided: {list(params.keys())}\n"
                                f"Please fix the parameters and retry."
                            )
                    
                except requests.exceptions.ConnectionError:
                    continue  # Try next host URL
                except requests.exceptions.Timeout:
                    logger.warning(f"[COMPOSIO_PLUGIN] Host callback timeout: {host_url}")
                    continue
            
            # No host available
            logger.info("[COMPOSIO_PLUGIN] Host callback not available, falling back to mock")
            self._host_callback_available = False
            return None
            
        except RuntimeError:
            # =====================================================================
            # CRITICAL FIX (arch-25): Re-raise RuntimeError (API failures)!
            # =====================================================================
            # RuntimeError is raised when Composio API returns success=False.
            # We MUST let this propagate to trigger TaskWeaver's retry loop!
            # =====================================================================
            raise
        except Exception as e:
            # Only catch network/import errors, not API failures
            logger.warning(f"[COMPOSIO_PLUGIN] Host callback failed (network error): {e}")
            self._host_callback_available = False
            return None
    
    def _describe_data_structure(self, data: Any, depth: int = 4, max_items: int = 5) -> str:
        """
        SCALABLE FIX (arch-35): Auto-describe response structure for LLM.
        
        Works for ANY API response - flights, spreadsheets, emails, etc.
        No hardcoding - recursively describes the actual structure.
        
        Examples:
        - Flights: {"results": {"best_flights": list[5]: [{"id", "price", ...}]}}
        - Sheets: {"spreadsheetId": "...", "replies": list[1]: [{"addSheet": {"properties": {...}}}]}
        - Gmail: list[10]: [{"id", "threadId", "labelIds": list[2], "snippet", ...}]
        
        Args:
            data: The API response data (ANY structure)
            depth: How deep to recurse (4 levels handles most APIs)
            max_items: Max keys/items to show (5 covers most important fields)
            
        Returns:
            Human-readable structure description
        """
        if data is None:
            return "null"
        
        if isinstance(data, str):
            # Show short strings as-is, truncate long ones
            if len(data) > 100:
                return f'string[{len(data)} chars]'
            elif len(data) > 40:
                return f'"{data[:35]}..."'
            return f'"{data}"'
        
        if isinstance(data, bool):
            return str(data).lower()
        
        if isinstance(data, (int, float)):
            return str(data)
        
        if isinstance(data, list):
            if len(data) == 0:
                return "[]"
            # Show first item structure to reveal the pattern
            if depth > 0:
                first_item = self._describe_data_structure(data[0], depth - 1, max_items)
                return f"list[{len(data)}]: [{first_item}, ...]"
            return f"list[{len(data)}]"
        
        if isinstance(data, dict):
            if len(data) == 0:
                return "{}"
            
            keys = list(data.keys())
            if depth > 0:
                # Show key-value pairs for important keys
                parts = []
                for key in keys[:max_items]:
                    val_desc = self._describe_data_structure(data[key], depth - 1, max_items)
                    parts.append(f'"{key}": {val_desc}')
                
                if len(keys) > max_items:
                    parts.append(f"+{len(keys) - max_items} more")
                
                return "{" + ", ".join(parts) + "}"
            else:
                # At max depth, just show key names
                shown = ", ".join(f'"{k}"' for k in keys[:max_items])
                if len(keys) > max_items:
                    shown += f", +{len(keys) - max_items} more"
                return "keys: [" + shown + "]"
        
        return type(data).__name__
    
    def _resolve_params(self, action_id: str, params: Dict[str, Any]) -> Dict[str, Any]:
        """
        Resolve TaskWeaver's param names to actual API param names using the tool schema.
        
        Follows the sql_pull_data pattern: accept approximate input, resolve internally.
        
        1. Fetch the actual schema for this action from DB
        2. For each param TaskWeaver provided, find matching schema param
        3. Use semantic similarity for fuzzy matching (e.g., name -> title)
        
        This is SCALABLE - uses actual schema, no hardcoding needed.
        
        Args:
            action_id: Resolved action ID
            params: Parameters from TaskWeaver (may have approximate names)
            
        Returns:
            Resolved parameters with correct API names
        """
        if not params:
            return params
            
        try:
            from apps.integrations.models import ComposioActionSchema
            
            # Get the action schema from DB
            action = ComposioActionSchema.objects.filter(
                action_id__iexact=action_id
            ).first()
            
            if not action or not action.parameters_schema:
                logger.debug(f"[COMPOSIO_PLUGIN] No schema for {action_id}, keeping original params")
                return params
            
            schema_props = action.parameters_schema.get('properties', {})
            if not schema_props:
                return params
            
            # Build resolved params using schema-based matching (NO HARDCODING)
            resolved = {}
            
            for param_key, param_value in params.items():
                # Use schema-based matching - fully dynamic
                matched_key = self._find_best_schema_match(param_key, schema_props)
                
                if matched_key and matched_key != param_key:
                    resolved[matched_key] = param_value
                    logger.info(f"[COMPOSIO_PLUGIN] Param resolved: {param_key} -> {matched_key}")
                else:
                    # Keep original - either exact match or no match found
                    resolved[param_key] = param_value
            
            return resolved
            
        except ImportError:
            # Django not available (simulation mode)
            return params
        except Exception as e:
            logger.warning(f"[COMPOSIO_PLUGIN] Param resolution error: {e}, using original")
            return params
    
    def _find_best_schema_match(self, param_name: str, schema_props: Dict[str, Any]) -> Optional[str]:
        """
        Find the best matching schema param for a TaskWeaver param name.
        
        Truly SCALABLE approach - uses the schema itself:
        1. Exact match (case-insensitive)
        2. Fuzzy string match (Levenshtein)
        3. Check if param_name appears in schema param's description
        
        No hardcoding - works for ANY tool's schema.
        
        Args:
            param_name: Parameter name from TaskWeaver
            schema_props: Schema properties dict {param_name: {description, type, ...}}
            
        Returns:
            Best matching schema param name, or None
        """
        param_lower = param_name.lower().replace('_', '')
        best_match = None
        best_score = 0
        
        for schema_key, schema_def in schema_props.items():
            schema_lower = schema_key.lower().replace('_', '')
            
            # 1. Exact match
            if param_lower == schema_lower:
                return schema_key
            
            # 2. Substring match (e.g., 'name' in 'spreadsheet_name' or vice versa)
            score = 0
            if param_lower in schema_lower or schema_lower in param_lower:
                score = 0.7
            
            # 3. Check schema description for the param name
            description = schema_def.get('description', '') if isinstance(schema_def, dict) else ''
            if description and param_name.lower() in description.lower():
                score = max(score, 0.8)  # Description match is strong signal
            
            # 4. Levenshtein-like similarity for typos
            if not score:
                # Simple character overlap ratio
                common = set(param_lower) & set(schema_lower)
                if len(common) / max(len(param_lower), len(schema_lower)) > 0.7:
                    score = 0.5
            
            if score > best_score:
                best_score = score
                best_match = schema_key
        
        return best_match if best_score >= 0.5 else None
    
    # =========================================================================
    # PARAMETER VALUE RESOLUTION (sql_pull_data pattern - PURE SCHEMA-DRIVEN)
    # =========================================================================
    # Resolves NAME ‚Üí ID automatically using ONLY schema information.
    # Works for ANY tool (800+) - ZERO hardcoding!
    # =========================================================================
    
    def _build_resolver_graph(self) -> Dict[str, List[Dict[str, Any]]]:
        """
        Build a graph mapping param types to actions that can PRODUCE them.
        
        PURE SCHEMA-DRIVEN - analyzes response schemas to discover:
        - Which actions produce ID fields in arrays (these are "resolver" actions)
        - What the param pattern should be (derived from field name + parent)
        
        Returns:
            Dict mapping param patterns to resolver actions
        """
        if self._resolver_graph is not None:
            return self._resolver_graph
        
        graph = {}
        
        try:
            cache = self._load_schema_cache()
            
            for action_id, entry in cache.items():
                if not isinstance(entry, dict):
                    continue
                
                # Handle both old format (entry = response_schema) and new format (entry = {response_schema, ...})
                if 'response_schema' in entry:
                    response_schema = entry['response_schema']
                else:
                    response_schema = entry  # Old format
                
                if not isinstance(response_schema, dict):
                    continue
                
                # Extract app prefix from action_id
                app_prefix = action_id.split('_')[0].upper() if '_' in action_id else ''
                
                # Find ID-producing arrays in response schema
                id_infos = self._find_id_producing_arrays(response_schema)
                
                for id_info in id_infos:
                    param_pattern = id_info['param_pattern']
                    
                    if param_pattern not in graph:
                        graph[param_pattern] = []
                    
                    # Get search param from input schema of this action
                    search_param = self._get_search_param_from_input_schema(action_id)
                    
                    graph[param_pattern].append({
                        'action': action_id,
                        'app': app_prefix,
                        'search_param': search_param,
                        'id_path': id_info['id_path'],
                        'name_path': id_info['name_path']
                    })
            
            ComposioAction._resolver_graph = graph
            logger.info(f"[COMPOSIO_PLUGIN] Built resolver graph: {len(graph)} param types from schema")
            return graph
            
        except Exception as e:
            logger.warning(f"[COMPOSIO_PLUGIN] Failed to build resolver graph: {e}")
            ComposioAction._resolver_graph = {}
            return {}
    
    def _find_id_producing_arrays(self, schema: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        Find arrays in schema that contain objects with ID fields.
        
        PURE SCHEMA-DRIVEN - recursively analyzes schema structure.
        No assumptions about field names - uses schema 'type' and structure.
        """
        results = []
        
        def analyze_schema(obj: Any, path: str, parent_array_name: str = ''):
            if not isinstance(obj, dict):
                return
            
            obj_type = obj.get('type')
            
            # If this is an array with items, check if items have ID fields
            if obj_type == 'array' and 'items' in obj:
                items = obj.get('items', {})
                if isinstance(items, dict):
                    item_props = items.get('properties', {})
                    
                    # Find ID field and name field in item properties
                    id_field = None
                    name_field = None
                    
                    for field_name, field_schema in item_props.items():
                        if not isinstance(field_schema, dict):
                            continue
                        
                        field_type = field_schema.get('type')
                        field_name_lower = field_name.lower()
                        
                        # Detect ID field by checking if name ends with 'id' and type is string
                        if field_type == 'string':
                            if field_name_lower == 'id' or field_name_lower.endswith('id') or field_name_lower.endswith('_id'):
                                id_field = field_name
                            # First string field that's not an ID could be the name field
                            elif name_field is None:
                                name_field = field_name
                    
                    if id_field:
                        # Derive param pattern from parent array name or ID field
                        if parent_array_name:
                            # Remove trailing 's' for singular: 'spreadsheets' -> 'spreadsheet'
                            singular = parent_array_name.rstrip('s') if parent_array_name.endswith('s') else parent_array_name
                            param_pattern = f"{singular}_id".lower()
                        else:
                            # Use ID field name: 'spreadsheetId' -> 'spreadsheet_id'
                            param_pattern = re.sub(r'(?<!^)(?=[A-Z])', '_', id_field).lower()
                        
                        # Normalize
                        param_pattern = param_pattern.replace('__', '_').strip('_')
                        if not param_pattern.endswith('_id'):
                            param_pattern = param_pattern.replace('_id_id', '_id')  # Fix double _id
                        
                        results.append({
                            'param_pattern': param_pattern,
                            'id_path': f"{path}[0].{id_field}",
                            'name_path': f"{path}[0].{name_field}" if name_field else None
                        })
            
            # Recurse into properties
            if 'properties' in obj:
                for prop_name, prop_schema in obj.get('properties', {}).items():
                    new_path = f"{path}.{prop_name}" if path else prop_name
                    # Pass array name as parent when recursing into array items
                    if isinstance(prop_schema, dict) and prop_schema.get('type') == 'array':
                        analyze_schema(prop_schema, new_path, prop_name)
                    else:
                        analyze_schema(prop_schema, new_path, parent_array_name)
            
            # Also check 'items' for arrays
            if 'items' in obj:
                analyze_schema(obj.get('items', {}), path, parent_array_name)
        
        # Start from root or data property
        data_schema = schema.get('properties', {}).get('data', schema)
        analyze_schema(data_schema, 'data' if 'data' in schema.get('properties', {}) else '', '')
        
        return results
    
    def _get_action_metadata(self, action_id: str) -> Optional[Dict[str, Any]]:
        """
        Get full action metadata from DB or cache file.
        
        Returns dict with:
        - parameters_schema: JSON schema for inputs
        - parameter_examples: Dict of param_name -> list of example values
        - response_schema: Expected response structure
        
        Falls back to cache file when Django is not available (Docker container).
        """
        if self._action_metadata_cache is None:
            ComposioAction._action_metadata_cache = {}
        
        if action_id in self._action_metadata_cache:
            return self._action_metadata_cache[action_id]
        
        # Try DB first (when Django is available)
        try:
            from apps.integrations.models import ComposioActionSchema
            action = ComposioActionSchema.objects.filter(action_id__iexact=action_id).first()
            
            if action:
                metadata = {
                    'parameters_schema': action.parameters_schema or {},
                    'parameter_examples': action.parameter_examples or {},
                    'response_schema': action.response_schema or {},
                    'response_examples': action.response_examples or [],  # ‚úÖ NEW: Include response examples
                    'description': action.description or ''
                }
                self._action_metadata_cache[action_id] = metadata
                return metadata
        except ImportError:
            # Django not available - fall through to cache
            pass
        
        # Fallback: Load from schema cache file (Docker container)
        cache = self._load_schema_cache()
        if cache:
            # Try exact match, then case-insensitive
            entry = cache.get(action_id) or cache.get(action_id.upper())
            
            if entry and isinstance(entry, dict):
                # New format: entry contains response_schema, parameter_examples, parameters_schema
                if 'response_schema' in entry or 'parameter_examples' in entry:
                    metadata = {
                        'parameters_schema': entry.get('parameters_schema', {}),
                        'parameter_examples': entry.get('parameter_examples', {}),
                        'response_schema': entry.get('response_schema', {}),
                        'response_examples': entry.get('response_examples', []),  # ‚úÖ NEW: Include response examples!
                        'description': entry.get('description', '')  # ‚úÖ FIX: Read description from cache
                    }
                else:
                    # Old format: entry IS the response_schema directly
                    metadata = {
                        'parameters_schema': {},
                        'parameter_examples': {},
                        'response_schema': entry,
                        'response_examples': [],
                        'description': ''
                    }
                
                self._action_metadata_cache[action_id] = metadata
                return metadata
        
        return None
    
    def _get_search_param_from_input_schema(self, action_id: str) -> str:
        """
        Get the search parameter name from action's INPUT schema.
        
        Uses parameters_schema from DB or cache file.
        """
        metadata = self._get_action_metadata(action_id)
        if not metadata:
            return 'query'
        
        params_schema = metadata.get('parameters_schema', {})
        if not params_schema:
            return 'query'
        
        props = params_schema.get('properties', {})
        required = set(params_schema.get('required', []))
        
        # Find first required string parameter
        for param_name, param_schema in props.items():
            if isinstance(param_schema, dict) and param_schema.get('type') == 'string':
                if param_name in required:
                    return param_name
        
        # Fallback: first string param
        for param_name, param_schema in props.items():
            if isinstance(param_schema, dict) and param_schema.get('type') == 'string':
                return param_name
        
        return 'query'
    
    def _value_matches_examples(self, value: str, examples: List[Any]) -> bool:
        """
        Check if value matches the format of provided examples.
        
        Uses parameter_examples from DB - no pattern hardcoding!
        
        Logic:
        1. If examples are empty, can't validate - return True
        2. Compare length characteristics
        3. Compare character class (spaces, special chars)
        4. If value looks very different from examples, return False
        """
        if not examples:
            return True  # No examples to compare
        
        # Filter to string examples only
        str_examples = [e for e in examples if isinstance(e, str)]
        if not str_examples:
            return True
        
        # Analyze example characteristics
        example_lengths = [len(e) for e in str_examples]
        min_len = min(example_lengths)
        max_len = max(example_lengths)
        avg_len = sum(example_lengths) / len(example_lengths)
        
        # Length check (with generous tolerance)
        if len(value) < min_len * 0.3 or len(value) > max_len * 3:
            # Value length is very different from examples
            logger.debug(f"[COMPOSIO_PLUGIN] Length mismatch: value={len(value)}, examples={min_len}-{max_len}")
            return False
        
        # Space check - if examples have no spaces but value has spaces
        examples_have_spaces = any(' ' in e for e in str_examples)
        if ' ' in value and not examples_have_spaces:
            logger.debug(f"[COMPOSIO_PLUGIN] Space mismatch: value has spaces, examples don't")
            return False
        
        # Character class similarity
        def char_profile(s: str) -> Set[str]:
            profile = set()
            if any(c.isdigit() for c in s):
                profile.add('digit')
            if any(c.isupper() for c in s):
                profile.add('upper')
            if any(c.islower() for c in s):
                profile.add('lower')
            if any(c in '-_' for c in s):
                profile.add('dash')
            if ' ' in s:
                profile.add('space')
            return profile
        
        # If value profile is very different from ALL examples, likely mismatch
        value_profile = char_profile(value)
        example_profiles = [char_profile(e) for e in str_examples]
        
        # Check if value profile overlaps with at least one example
        has_overlap = any(len(value_profile & ep) >= len(value_profile) * 0.5 for ep in example_profiles)
        if not has_overlap and len(value_profile) > 1:
            logger.debug(f"[COMPOSIO_PLUGIN] Profile mismatch: value={value_profile}")
            return False
        
        return True
    
    def _is_obvious_placeholder(self, value: str, param_name: str, action_id: str = None) -> bool:
        """
        Detect obvious placeholder values using SCHEMA-FIRST approach.
        
        Priority:
        1. Check schema for enum/pattern validation (SCALABLE)
        2. Fall back to obvious pattern matching (CONSERVATIVE)
        
        Returns True ONLY if value is clearly a placeholder.
        """
        value_lower = value.lower()
        
        # =================================================================
        # STEP 1: OBVIOUS PLACEHOLDER PATTERNS (High confidence)
        # =================================================================
        # Only flag things that are CLEARLY placeholders
        obvious_placeholder_patterns = [
            'your_', '_here', 'replace_', 'example_', 'sample_',
            'placeholder', 'insert_', 'todo_', 'xxx', '{{', '}}',
            '<your', '<insert', '<replace', '[your', '[insert'
        ]
        for pattern in obvious_placeholder_patterns:
            if pattern in value_lower:
                print(f"[COMPOSIO_PLUGIN] üö® PLACEHOLDER detected: {param_name}='{value}' (matched '{pattern}')")
                return True
        
        # =================================================================
        # STEP 2: SCHEMA-BASED VALIDATION (Scalable)
        # =================================================================
        # If we have schema info, use it to validate
        if action_id:
            metadata = self._get_action_metadata(action_id)
            if metadata:
                params_schema = metadata.get('parameters_schema', {})
                param_props = params_schema.get('properties', {}).get(param_name, {})
                
                # Check if schema has enum - value must be in enum
                if 'enum' in param_props:
                    enum_values = param_props['enum']
                    if value not in enum_values:
                        print(f"[COMPOSIO_PLUGIN] üö® VALUE not in enum: {param_name}='{value}' (valid: {enum_values[:5]}...)")
                        return True
                    return False  # Value is valid per schema
                
                # Check if schema has pattern - value must match regex
                if 'pattern' in param_props:
                    pattern = param_props['pattern']
                    try:
                        if not re.match(pattern, value):
                            print(f"[COMPOSIO_PLUGIN] üö® VALUE doesn't match pattern: {param_name}='{value}' (pattern: {pattern})")
                            return True
                        return False  # Value matches pattern
                    except re.error:
                        pass  # Invalid regex, skip
                
                # Check if schema has format hint
                format_hint = param_props.get('format', '')
                if format_hint == 'uuid' and not self._looks_like_uuid(value):
                    print(f"[COMPOSIO_PLUGIN] üö® VALUE doesn't look like UUID: {param_name}='{value}'")
                    return True
        
        # =================================================================
        # STEP 3: CONSERVATIVE FALLBACK
        # =================================================================
        # Only flag if it REALLY looks like a placeholder (has spaces in ID field)
        param_lower = param_name.lower()
        is_id_param = param_lower.endswith('id') or param_lower.endswith('_id')
        
        if is_id_param and ' ' in value:
            # ID params should not contain spaces - likely a name that needs resolution
            print(f"[COMPOSIO_PLUGIN] üö® ID param has spaces: {param_name}='{value}' - needs resolution")
            return True
        
        # Default: Trust the LLM's value
        return False
    
    def _looks_like_uuid(self, value: str) -> bool:
        """Check if value looks like a UUID."""
        uuid_pattern = r'^[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}$'
        return bool(re.match(uuid_pattern, value))
    
    def _has_resolver_for_param(self, param_name: str) -> bool:
        """
        Check if a MEANINGFUL resolver exists for this parameter in the resolver_graph.
        
        SCALABLE ARCHITECTURE:
        - Returns True if a SPECIFIC search/list action can resolve this parameter
        - Returns False if no specific resolver OR only generic meta-actions exist
        - Filters out meta-actions (COMPOSIO_SEARCH_TOOLS, etc.) - these aren't real resolvers
        - Fully dynamic - no hardcoding of specific parameters!
        
        Examples:
        - departure_id: Only COMPOSIO_SEARCH_TOOLS ‚Üí NO meaningful resolver ‚Üí collect directly
        - product_id: PRODUCT_SEARCH exists ‚Üí meaningful resolver ‚Üí use search
        - user_id: USER_LIST exists ‚Üí meaningful resolver ‚Üí use list
        """
        try:
            # Meta-actions that are NOT meaningful resolvers
            # These are tool discovery actions - they search for OTHER tools, not data
            META_ACTIONS = {
                'COMPOSIO_SEARCH_TOOLS',
                'COMPOSIO_GET_TOOLS',
                'COMPOSIO_LIST_TOOLS',
            }
            
            # Build resolver graph
            resolver_graph = self._build_resolver_graph()
            
            # Normalize param name
            param_key = re.sub(r'(?<!^)(?=[A-Z])', '_', param_name).lower()
            
            # Find all resolvers for this param
            resolvers = []
            
            # Check exact match
            if param_key in resolver_graph:
                resolvers.extend(resolver_graph[param_key])
            
            # Try semantic variations ONLY if no exact match
            # SCALABLE: Match based on shared prefix/suffix, not generic substrings
            if not resolvers:
                # Extract the base entity name (e.g., "departure" from "departure_id")
                param_base = param_key.replace('_id', '').replace('_', '')
                
                for key in resolver_graph.keys():
                    key_base = key.replace('_id', '').replace('_', '')
                    
                    # Match if they share significant semantic overlap
                    # Example: "departure_id" ‚Üî "departure_airport_id" (YES)
                    # Example: "departure_id" ‚Üî "product_id" (NO)
                    if len(param_base) >= 3 and len(key_base) >= 3:
                        if param_base in key_base or key_base in param_base:
                            resolvers.extend(resolver_graph[key])
                            break
            
            # Filter out meta-actions - these don't count as meaningful resolvers
            meaningful_resolvers = [
                r for r in resolvers 
                if r.get('action', '').upper() not in META_ACTIONS
            ]
            
            # Has meaningful resolver only if we found non-meta actions
            has_meaningful = len(meaningful_resolvers) > 0
            
            # Debug logging to see what's happening
            if resolvers:
                print(
                    f"[COMPOSIO_PLUGIN] üîç Resolver check for '{param_name}': "
                    f"total={len(resolvers)}, meaningful={len(meaningful_resolvers)}"
                )
                if not has_meaningful:
                    print(
                        f"[COMPOSIO_PLUGIN] ‚ö†Ô∏è Only meta-actions found for '{param_name}': "
                        f"{[r.get('action') for r in resolvers]} - will suggest direct collection"
                    )
            
            return has_meaningful
            
        except Exception as e:
            logger.debug(f"[COMPOSIO_PLUGIN] Error checking resolver for {param_name}: {e}")
            # Safe fallback: assume NO resolver (collect directly)
            # This prevents suggesting search when we're unsure
            return False
    
    def _suggest_search_action(self, action_name: str, param_name: str) -> str:
        """
        Dynamically suggest a SEARCH action based on the current action and parameter.
        
        Uses resolver_graph to find appropriate search actions.
        NO HARDCODING - suggestions come from the schema cache.
        """
        try:
            # Get app prefix from action name
            app_prefix = action_name.split('_')[0].upper() if '_' in action_name else ''
            
            # Build resolver graph to find search actions
            resolver_graph = self._build_resolver_graph()
            
            # Normalize param name
            param_key = re.sub(r'(?<!^)(?=[A-Z])', '_', param_name).lower()
            
            # Find resolvers for this param type
            resolvers = resolver_graph.get(param_key, [])
            
            # Try variations
            if not resolvers:
                for key in resolver_graph.keys():
                    if param_key in key or key in param_key:
                        resolvers = resolver_graph[key]
                        break
            
            # Prefer same-app resolvers
            best_resolver = None
            for r in resolvers:
                if r.get('app', '').upper() == app_prefix:
                    best_resolver = r
                    break
            if not best_resolver and resolvers:
                best_resolver = resolvers[0]
            
            if best_resolver:
                return f"For example, use {best_resolver['action_id']} to find the {param_name}."
            
            # Fallback: suggest generic search pattern
            if app_prefix:
                return f"Look for a {app_prefix}_SEARCH_* or {app_prefix}_LIST_* action to find the {param_name}."
            
            return f"Use an appropriate SEARCH or LIST action to find the {param_name}."
            
        except Exception as e:
            logger.debug(f"[COMPOSIO_PLUGIN] Error suggesting search action: {e}")
            return f"Use an appropriate SEARCH action to find the {param_name}."
    
    def _suggest_similar_actions(self, action_name: str) -> str:
        """
        When an action doesn't exist, suggest similar actions that DO exist.
        Helps LLM correct hallucinated action names.
        
        FULLY DYNAMIC - no hardcoded terms:
        - Analyzes actual action names in the cache
        - Uses fuzzy matching on all parts of the action name
        - Works for any tool/action pattern
        """
        try:
            # Load schema cache
            cache = self._load_schema_cache()
            if not cache:
                return "Check available actions in the system."
            
            action_upper = action_name.upper()
            parts = action_upper.split('_')
            all_actions = list(cache.keys())
            
            # Score-based matching for flexibility
            scored_matches = []
            
            for existing_action in all_actions:
                score = 0
                existing_upper = existing_action.upper()
                existing_parts = existing_upper.split('_')
                
                # Score 1: Same app prefix (first part)
                if parts and existing_parts and parts[0] == existing_parts[0]:
                    score += 3
                
                # Score 2: Matching parts (any position)
                matching_parts = set(parts) & set(existing_parts)
                score += len(matching_parts) * 2
                
                # Score 3: Substring match (entity names)
                for part in parts:
                    if len(part) > 2:  # Skip short parts like "A", "TO"
                        if part in existing_upper:
                            score += 1
                        # Singular/plural variations
                        elif part.rstrip('S') in existing_upper or part + 'S' in existing_upper:
                            score += 0.5
                
                if score > 0:
                    scored_matches.append((existing_action, score))
            
            # Sort by score (highest first) and take top 5
            scored_matches.sort(key=lambda x: x[1], reverse=True)
            similar_actions = [action for action, score in scored_matches[:5]]
            
            if similar_actions:
                return f"Did you mean one of these actions? {', '.join(similar_actions)}"
            else:
                # Fallback: show actions with same first letter
                first_letter = action_upper[0] if action_upper else ''
                fallback = [a for a in all_actions if a.startswith(first_letter)][:3]
                if fallback:
                    return f"Action not found. Some actions starting with '{first_letter}': {', '.join(fallback)}"
                return "This action does not exist. Please check available actions."
                
        except Exception as e:
            logger.debug(f"[COMPOSIO_PLUGIN] Error suggesting similar actions: {e}")
            return "This action does not exist. Please use a valid action."
    
    def _resolve_param_values(
        self,
        action_id: str,
        params: Dict[str, Any],
        entity_id: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Resolve parameter VALUES (name ‚Üí id) using DB metadata.
        
        Uses parameter_examples from ComposioActionSchema to detect mismatches.
        Uses response_schema from other actions to find resolvers.
        
        NO HARDCODING - everything comes from DB!
        
        Args:
            action_id: The action being called
            params: Parameters from TaskWeaver
            entity_id: User entity for auth
            
        Returns:
            Params with resolved values
        """
        print(f"[COMPOSIO_PLUGIN] üîç VALUE_RESOLUTION: Starting for {action_id} with params: {list(params.keys())}")
        
        if not params:
            print(f"[COMPOSIO_PLUGIN] üîç VALUE_RESOLUTION: No params to resolve")
            return params
        
        # Get action metadata from DB (includes parameter_examples)
        metadata = self._get_action_metadata(action_id)
        if not metadata:
            print(f"[COMPOSIO_PLUGIN] üîç VALUE_RESOLUTION: No metadata found for {action_id}")
            return params
        
        parameter_examples = metadata.get('parameter_examples', {})
        print(f"[COMPOSIO_PLUGIN] üîç VALUE_RESOLUTION: Found {len(parameter_examples)} param examples: {list(parameter_examples.keys())}")
        
        # Build resolver graph from response schemas (cached)
        resolver_graph = self._build_resolver_graph()
        
        resolved = params.copy()
        app_prefix = action_id.split('_')[0].upper() if '_' in action_id else ''
        
        for param_name, param_value in params.items():
            if not isinstance(param_value, str) or not param_value:
                continue
            
            # Get examples for this parameter from DB
            examples = parameter_examples.get(param_name, [])
            
            # Also check camelCase/snake_case variations
            if not examples:
                param_snake = re.sub(r'(?<!^)(?=[A-Z])', '_', param_name).lower()
                for key, val in parameter_examples.items():
                    if re.sub(r'(?<!^)(?=[A-Z])', '_', key).lower() == param_snake:
                        examples = val
                        break
            
            # Check if value matches examples format (if we have examples)
            if examples and self._value_matches_examples(param_value, examples):
                print(f"[COMPOSIO_PLUGIN] üîç VALUE_RESOLUTION: {param_name}='{param_value}' matches examples format")
                continue  # Value format looks valid
            
            # FALLBACK: Detect obvious placeholder patterns without needing examples
            # This catches: 'your_spreadsheet_id_here', 'sample_value', etc.
            is_placeholder = self._is_obvious_placeholder(param_value, param_name, action_id)
            if not is_placeholder:
                # Doesn't look like placeholder - assume valid
                continue
            
            print(f"[COMPOSIO_PLUGIN] üîç VALUE_RESOLUTION: {param_name}='{param_value}' needs resolution")
            
            # Value doesn't match - need to resolve
            # Normalize param name for resolver lookup
            param_key = re.sub(r'(?<!^)(?=[A-Z])', '_', param_name).lower()
            
            # Find resolvers for this param type
            resolvers = resolver_graph.get(param_key, [])
            if not resolvers:
                # Try variations
                for key in resolver_graph.keys():
                    if key.replace('_', '') == param_key.replace('_', ''):
                        resolvers = resolver_graph[key]
                        break
            
            if not resolvers:
                continue
            
            # Find best resolver (prefer same app)
            best_resolver = None
            for r in resolvers:
                if r['app'] == app_prefix:
                    best_resolver = r
                    break
            if not best_resolver:
                best_resolver = resolvers[0]
            
            # Execute resolver
            logger.info(f"[COMPOSIO_PLUGIN] üîç Resolving {param_name}='{param_value}' via {best_resolver['action']}")
            
            try:
                resolved_id = self._execute_resolver(
                    resolver=best_resolver,
                    search_value=param_value,
                    entity_id=entity_id
                )
                
                if resolved_id:
                    resolved[param_name] = resolved_id
                    logger.info(f"[COMPOSIO_PLUGIN] ‚úÖ Resolved: '{param_value}' ‚Üí '{resolved_id}'")
                    
            except Exception as e:
                logger.warning(f"[COMPOSIO_PLUGIN] Resolution error: {e}")
        
        return resolved
    
    def _execute_resolver(
        self,
        resolver: Dict[str, Any],
        search_value: str,
        entity_id: Optional[str] = None
    ) -> Optional[str]:
        """
        Execute a resolver action to convert name ‚Üí id.
        
        Uses schema-derived info to call search and extract ID.
        """
        action_id = resolver['action']
        search_param = resolver['search_param']
        id_path = resolver['id_path']
        name_path = resolver.get('name_path')
        
        search_params = {search_param: search_value}
        
        try:
            if self._is_simulation_mode():
                result, _ = self._get_mock_response(action_id, search_params)
            else:
                service = self._get_service()
                
                if not entity_id:
                    entity_id = self.ctx.get_session_var("_composio_entity_id", None) or \
                                self.config.get('entity_id', 'default')
                
                exec_result = service.execute_action(
                    action_name=action_id,
                    params=search_params,
                    entity_id=entity_id
                )
                
                if not (exec_result.get('success') or exec_result.get('successfull')):
                    return None
                
                result = exec_result.get('data', exec_result)
            
            # Extract ID using schema-derived path
            return self._extract_by_path(result, id_path, search_value, name_path)
            
        except Exception as e:
            logger.warning(f"[COMPOSIO_PLUGIN] Resolver failed: {e}")
            return None
    
    def _extract_by_path(
        self,
        data: Any,
        id_path: str,
        search_value: str,
        name_path: Optional[str] = None
    ) -> Optional[str]:
        """
        Extract value from data using schema-derived path.
        
        Navigates path like 'data.items[0].id' and matches by name if possible.
        """
        if not data or not isinstance(data, dict):
            return None
        
        def navigate(obj: Any, path_parts: List[str], match_name: bool = False):
            if not path_parts or obj is None:
                return obj
            
            part = path_parts[0]
            remaining = path_parts[1:]
            
            # Handle array notation: 'items[0]'
            array_match = re.match(r'(\w+)\[(\d+)\]', part)
            if array_match:
                key, idx = array_match.groups()
                if isinstance(obj, dict) and key in obj:
                    arr = obj[key]
                    if isinstance(arr, list) and arr:
                        # If we have a name path, try to match by name
                        if match_name and name_path:
                            name_parts = name_path.split('.')
                            # Find the name field in array items
                            for item in arr:
                                if isinstance(item, dict):
                                    # Try to get name from item
                                    name_val = self._get_nested_value(item, name_parts[-1:])
                                    if name_val and str(name_val).lower() == search_value.lower():
                                        return navigate(item, remaining, False)
                        # Fallback to index
                        idx_int = int(idx)
                        if len(arr) > idx_int:
                            return navigate(arr[idx_int], remaining, match_name)
                return None
            
            # Regular key access
            if isinstance(obj, dict) and part in obj:
                return navigate(obj[part], remaining, match_name)
            
            return None
        
        try:
            path_parts = id_path.split('.')
            result = navigate(data, path_parts, match_name=True)
            
            if isinstance(result, str):
                return result
            elif isinstance(result, dict):
                # Try to find any 'id' field in the result
                for key, val in result.items():
                    if key.lower().endswith('id') and isinstance(val, str):
                        return val
            
            return None
        except Exception:
            return None
    
    def _get_nested_value(self, obj: Any, path_parts: List[str]) -> Any:
        """Get nested value from object using path parts."""
        current = obj
        for part in path_parts:
            if isinstance(current, dict) and part in current:
                current = current[part]
            else:
                return None
        return current
    
    def _resolve_action(self, action_name: str) -> str:
        """
        Resolve TaskWeaver's action name to actual DB action ID.
        
        Follows the sql_pull_data pattern: accept approximate input, resolve internally.
        
        1. Check if exact action exists in DB
        2. If not, use semantic search to find best match
        3. Return resolved action ID
        
        Args:
            action_name: Action name from TaskWeaver (may be conceptual/approximate)
            
        Returns:
            Resolved action ID that exists in the database
        """
        try:
            from apps.integrations.models import ComposioActionSchema
            
            # Step 1: Try exact match (case-insensitive)
            exact_match = ComposioActionSchema.objects.filter(
                action_id__iexact=action_name
            ).first()
            
            if exact_match:
                logger.debug(f"[COMPOSIO_PLUGIN] Exact match: {action_name}")
                return exact_match.action_id
            
            # Step 2: Use semantic search (reuse existing action_matcher)
            logger.info(f"[COMPOSIO_PLUGIN] '{action_name}' not in DB, resolving semantically...")
            
            # Extract app hint from action name (e.g., GMAIL_GET_LAST_EMAILS -> gmail)
            app_hint = None
            if '_' in action_name and action_name.isupper():
                app_hint = action_name.split('_')[0].lower()
            
            # Get or create action matcher (reuse existing implementation)
            if self._action_matcher is None:
                from apps.integrations.services.action_matcher import ComposioActionMatcher
                self._action_matcher = ComposioActionMatcher(enable_warmup=False)
            
            # Use the action name as the search query
            # Also try the human-readable version: GMAIL_GET_LAST_EMAILS -> "get last emails"
            search_query = action_name.replace('_', ' ').lower()
            if app_hint:
                search_query = search_query.replace(app_hint, '').strip()
            
            results = self._action_matcher.match_for_subtask(
                subtask_description=search_query,
                app_hints=[app_hint] if app_hint else None,
                top_k_apps=1,
                top_k_actions_per_app=1,
                min_confidence=0.3  # Lower threshold for resolution
            )
            
            if results:
                resolved = results[0]['action_id']
                confidence = results[0]['confidence']
                logger.info(
                    f"[COMPOSIO_PLUGIN] Resolved: {action_name} -> {resolved} "
                    f"(confidence: {confidence:.2f})"
                )
                return resolved
            
            # No match found - return original (will fail at execution with clear error)
            logger.warning(f"[COMPOSIO_PLUGIN] Could not resolve: {action_name}")
            return action_name
            
        except ImportError:
            # Django not available (simulation mode) - return as-is
            logger.debug(f"[COMPOSIO_PLUGIN] Resolution skipped (simulation mode)")
            return action_name
        except Exception as e:
            logger.warning(f"[COMPOSIO_PLUGIN] Resolution error: {e}, using original")
            return action_name
    
    def _get_mock_response(self, action_name: str, params: Dict[str, Any]) -> Tuple[Dict[str, Any], str]:
        """
        Generate mock response for simulation mode.
        
        SINGLE SOURCE OF TRUTH: ComposioActionSchema.response_schema in DB
        ===================================================================
        
        All mock data is generated from the response_schema stored in DB.
        No hardcoded patterns, no verb-based fallbacks, no app-specific logic.
        
        If response_schema is missing, that's a DATA problem - fix in DB, not code.
        """
        # =====================================================================
        # STEP 1: Try HOST CALLBACK - Real API execution via Django host
        # =====================================================================
        host_result = self._call_host_api(action_name, params)
        if host_result is not None:
            return host_result
        
        # =====================================================================
        # STEP 2: SINGLE SOURCE OF TRUTH - Schema from DB
        # =====================================================================
        schema_based_mock = self._generate_schema_based_mock(action_name, params)
        
        if schema_based_mock:
            logger.info(f"[COMPOSIO_PLUGIN] SIMULATION: {action_name} -> schema-based mock from DB")
            return schema_based_mock
        
        # =====================================================================
        # FALLBACK: Minimal success response (schema missing - DATA issue)
        # =====================================================================
        # If we get here, the action doesn't exist or isn't synced.
        # Return a CLEAR ERROR so LLM doesn't keep retrying with non-existent action.
        logger.warning(f"[COMPOSIO_PLUGIN] ACTION NOT FOUND: {action_name} - this action may not exist!")
        
        # Suggest similar actions that DO exist
        suggestion = self._suggest_similar_actions(action_name)
        
        mock_data = {
            'success': False, 
            'error': f"ACTION '{action_name}' DOES NOT EXIST. {suggestion}",
            '_action_not_found': True
        }
        description = (
            f"ERROR: Action {action_name} does not exist in the system.\n"
            f"{suggestion}\n"
            f"Please use a different action or approach."
        )
        return mock_data, description
    
    def _unwrap_and_describe_mock(self, full_mock: Dict[str, Any], action_name: str) -> Tuple[Dict[str, Any], str]:
        """
        Helper to unwrap 'data' field and generate description (DRY principle).
        
        Real API returns: result.get('data', result) - so mock must match.
        
        CRITICAL: Successful responses are UNWRAPPED (no 'success' field).
        Only error responses have {'success': False, 'error': '...'}.
        """
        if isinstance(full_mock, dict) and 'data' in full_mock:
            mock_data = full_mock['data']
        else:
            mock_data = full_mock
        
        # ‚ùå DO NOT add 'success': True here!
        # Successful responses are unwrapped and don't have 'success' field.
        # Only error responses (placeholder detection) have 'success': False.
        
        # =====================================================================
        # SPECIAL CASE: COMPOSIO_SEARCH_TOOLS returns 'results' array directly
        # =====================================================================
        # In real execution, COMPOSIO_SEARCH_TOOLS returns just the results array,
        # not the full data object. This ensures mock behavior matches real API.
        # When no tools are found, return [] (empty list) so LLM can detect it.
        # =====================================================================
        if action_name == "COMPOSIO_SEARCH_TOOLS" and isinstance(mock_data, dict) and 'results' in mock_data:
            mock_data = mock_data['results']  # Unwrap to just the results array
        
        # =====================================================================
        # TASKWEAVER PATTERN: Explicit description for empty results
        # =====================================================================
        # Follow sql_pull_data.py pattern: Tell LLM explicitly when results are empty
        # This is more scalable than expecting LLM to check len(results) == 0
        # =====================================================================
        if action_name == "COMPOSIO_SEARCH_TOOLS":
            if isinstance(mock_data, list) and len(mock_data) == 0:
                description = (
                    f"Successfully executed {action_name}.\n"
                    f"The search returned NO matching tools (empty list: []).\n"
                    f"No tools were found that match your search criteria.\n"
                    f"Consider collecting the required data directly from the user instead."
                )
            else:
                # CRITICAL: mock_data is ALREADY the list (unwrapped from 'results')
                # Make this crystal clear in the description!
                description = (
                    f"Successfully executed {action_name}.\n"
                    f"Found {len(mock_data) if isinstance(mock_data, list) else 'N/A'} matching tool(s).\n"
                    f"IMPORTANT: The returned data IS the list directly (already unwrapped).\n"
                    f"Access elements with: result[0], result[1], etc.\n"
                    f"Each element structure: {self._describe_data_structure(mock_data[0]) if isinstance(mock_data, list) and len(mock_data) > 0 else 'N/A'}"
                )
        else:
            # Use dynamic structure hint (same as real API)
            structure_hint = self._describe_data_structure(mock_data)
            
            description = (
                f"Successfully executed {action_name}.\n"
                f"RESPONSE STRUCTURE: {structure_hint}\n"
                f"Use the structure above to access the data correctly."
            )
        
        return mock_data, description
    
    def _generate_schema_based_mock(self, action_name: str, params: Dict[str, Any]) -> Optional[Tuple[Dict[str, Any], str]]:
        """
        Generate mock response based on actual Composio action schema from DB.
        
        FULLY DYNAMIC (TaskWeaver sql_pull_data pattern):
        - Fetches response_schema from ComposioActionSchema table
        - Generates conformant mock data based on schema
        - No hardcoding - works for all 800+ tools!
        
        THE ARCHITECTURAL FIX:
        =====================
        If this returns None, it means the action's response_schema is missing from DB.
        The fix is to populate ComposioActionSchema.response_schema for all actions.
        This is DATA, not CODE - the schema-driven approach scales to any number of tools.
        
        Returns:
            (mock_data, description) or None if schema not available
        """
        try:
            from apps.integrations.models import ComposioActionSchema
            
            # Fetch schema from DB
            action = ComposioActionSchema.objects.filter(
                action_id__iexact=action_name
            ).first()
            
            if not action:
                logger.warning(f"[COMPOSIO_PLUGIN] ACTION NOT IN DB: {action_name} - add to ComposioActionSchema table")
                return None
            
            if not action.response_schema:
                logger.warning(f"[COMPOSIO_PLUGIN] NO RESPONSE_SCHEMA: {action_name} - populate response_schema in DB")
                return None
            
            response_schema = action.response_schema
            
            # Generate mock based on schema properties
            full_mock = self._generate_mock_from_schema(response_schema)
            
            logger.info(f"[COMPOSIO_PLUGIN] SCHEMA-BASED mock for {action_name} (from DB)")
            return self._unwrap_and_describe_mock(full_mock, action_name)
            
        except ImportError:
            # Django not available (running in Docker without Django context)
            # Try loading from schema cache file instead
            print(f"[COMPOSIO_PLUGIN] Django not available, trying schema cache for {action_name}")
            return self._generate_mock_from_cache(action_name, params)
        except Exception as e:
            print(f"[COMPOSIO_PLUGIN] Schema lookup failed for {action_name}: {e}")
            return self._generate_mock_from_cache(action_name, params)
    
    def _generate_mock_from_cache(self, action_name: str, params: Dict[str, Any]) -> Optional[Tuple[Dict[str, Any], str]]:
        """Generate mock from cached schema file (Docker container fallback)."""
        cache = self._load_schema_cache()
        
        # Try exact match first, then case-insensitive
        entry = cache.get(action_name) or cache.get(action_name.upper())
        
        if not entry:
            print(f"[COMPOSIO_PLUGIN] Schema not in cache: {action_name}")
            return None
        
        # Handle both old format (entry = response_schema) and new format (entry = {response_schema, ...})
        if isinstance(entry, dict) and 'response_schema' in entry:
            response_schema = entry['response_schema']
            response_examples = entry.get('response_examples', {})
        else:
            response_schema = entry  # Old format
            response_examples = {}
        
        print(f"[COMPOSIO_PLUGIN] Found schema in cache for {action_name}")
        
        # SCALABLE PRIORITY:
        # 1. Use response_examples if available AND useful (actual examples from Composio API)
        # 2. Fall back to schema-based generation with property name inference
        full_mock = None
        
        if response_examples and isinstance(response_examples, dict) and len(response_examples) > 0:
            print(f"[COMPOSIO_PLUGIN] ‚úÖ Using response_examples for {action_name} (SCALABLE)")
            merged = self._merge_examples_with_schema(response_schema, response_examples)
            
            # Validate merged result is useful (not empty/trivial)
            if merged and isinstance(merged, dict) and len(merged) > 0:
                full_mock = merged
            else:
                print(f"[COMPOSIO_PLUGIN] ‚ö†Ô∏è response_examples produced empty result, falling back to schema")
        
        if full_mock is None:
            # Fall back to schema-based generation
            full_mock = self._generate_mock_from_schema(response_schema)
        
        print(f"[COMPOSIO_PLUGIN] Generated mock from cache for {action_name}")
        
        # Get the data and description
        mock_data, description = self._unwrap_and_describe_mock(full_mock, action_name)
        
        # ‚úÖ CRITICAL: Print description so LLM can see it in execution logs!
        # TaskWeaver shows printed output to the LLM, not just return values.
        # This follows the sql_pull_data pattern where descriptions guide the LLM.
        print(f"\n{description}\n")
        
        return mock_data, description
    
    def _get_schema_max_depth(self, schema: Dict[str, Any], current: int = 0, visited: set = None) -> int:
        """Calculate the maximum nesting depth of a schema dynamically."""
        if visited is None:
            visited = set()
        
        # Prevent infinite recursion from circular refs
        schema_id = id(schema)
        if schema_id in visited:
            return current
        visited.add(schema_id)
        
        max_depth = current
        schema_type = schema.get('type', 'object')
        
        if schema_type == 'object':
            for prop_schema in schema.get('properties', {}).values():
                if isinstance(prop_schema, dict):
                    max_depth = max(max_depth, self._get_schema_max_depth(prop_schema, current + 1, visited))
        elif schema_type == 'array':
            items = schema.get('items', {})
            if isinstance(items, dict):
                max_depth = max(max_depth, self._get_schema_max_depth(items, current + 1, visited))
        
        return max_depth
    
    def _merge_examples_with_schema(self, schema: Dict[str, Any], examples: Dict[str, Any], depth: int = 0, max_depth: int = None) -> Any:
        """
        Merge response_examples with schema structure for complete mock data.
        
        SCALABLE: Uses actual examples from Composio API when available.
        Falls back to schema-based generation for fields without examples.
        
        IMPORTANT: Handles wrapper structures like { data: { spreadsheets: [...] } }
        by recursively merging nested objects even if examples are partial.
        
        Args:
            schema: The response JSON schema
            examples: Extracted examples from response_schema
            depth: Current recursion depth
            max_depth: Dynamic max depth (calculated from schema if not provided)
            
        Returns:
            Complete mock data with examples merged in
        """
        # Calculate max_depth dynamically on first call
        if max_depth is None:
            max_depth = min(self._get_schema_max_depth(schema) + 2, 15)  # Add buffer, cap at 15
        
        if depth > max_depth:
            return {}
        
        schema_type = schema.get('type', 'object')
        
        if schema_type == 'object':
            properties = schema.get('properties', {})
            result = {}
            
            for prop_name, prop_schema in list(properties.items())[:15]:
                example_value = examples.get(prop_name) if isinstance(examples, dict) else None
                
                # Check if example is useful (not empty dict/list, not None)
                example_is_useful = (
                    example_value is not None and
                    example_value != {} and
                    example_value != [] and
                    example_value != ''
                )
                
                if example_is_useful:
                    # For nested objects, recursively merge
                    if prop_schema.get('type') == 'object' and isinstance(example_value, dict):
                        result[prop_name] = self._merge_examples_with_schema(
                            prop_schema, example_value, depth + 1, max_depth
                        )
                    # For arrays, check if it has useful content
                    elif prop_schema.get('type') == 'array' and isinstance(example_value, list):
                        # RECURSIVELY merge array items with items schema
                        items_schema = prop_schema.get('items', {})
                        items_type = items_schema.get('type', 'unknown')
                        
                        if len(example_value) > 0 and items_type == 'object':
                            # Merge each array item with the items schema to add missing fields
                            merged_items = []
                            for item in example_value[:3]:
                                if isinstance(item, dict):
                                    merged = self._merge_examples_with_schema(items_schema, item, depth + 1, max_depth)
                                    merged_items.append(merged)
                                else:
                                    merged_items.append(item)
                            result[prop_name] = merged_items if merged_items else [self._generate_mock_from_schema(items_schema, depth + 1, prop_name, max_depth)]
                        else:
                            # Empty array or primitive items - generate from schema
                            result[prop_name] = self._generate_mock_from_schema(prop_schema, depth + 1, prop_name, max_depth)
                    else:
                        # Use primitive example value directly
                        result[prop_name] = example_value
                else:
                    # No useful example - generate from schema
                    result[prop_name] = self._generate_mock_from_schema(prop_schema, depth + 1, prop_name, max_depth)
            
            return result
        
        elif schema_type == 'array':
            items_schema = schema.get('items', {})
            items_type = items_schema.get('type', 'unknown')
            print(f"[COMPOSIO_PLUGIN] MERGE ARRAY: examples={type(examples)}, len={len(examples) if isinstance(examples, list) else 'N/A'}, items_type={items_type}")
            
            # If we have array examples, MERGE each item with the items schema
            # This ensures missing fields like 'id', 'name' are added from schema
            if isinstance(examples, list) and len(examples) > 0:
                merged_items = []
                for idx, item_example in enumerate(examples[:3]):  # Limit to 3 items
                    print(f"[COMPOSIO_PLUGIN]   Item {idx}: type={type(item_example)}, keys={list(item_example.keys()) if isinstance(item_example, dict) else 'N/A'}")
                    if isinstance(item_example, dict) and items_type == 'object':
                        # Recursively merge each array item with the items schema
                        merged_item = self._merge_examples_with_schema(items_schema, item_example, depth + 1, max_depth)
                        print(f"[COMPOSIO_PLUGIN]   Merged keys: {list(merged_item.keys()) if isinstance(merged_item, dict) else 'N/A'}")
                        merged_items.append(merged_item)
                    elif item_example not in [None, {}, '', []]:
                        merged_items.append(item_example)
                if merged_items:
                    return merged_items
            # Otherwise generate from schema
            return [self._generate_mock_from_schema(items_schema, depth + 1, "", max_depth)]
        
        else:
            # For primitive types, use example if available and not empty
            if examples is not None and examples != '' and examples != {} and examples != []:
                return examples
            return self._generate_mock_from_schema(schema, depth, "", max_depth)
    
    def _generate_mock_from_schema(self, schema: Dict[str, Any], depth: int = 0, prop_name: str = "", max_depth: int = None) -> Any:
        """
        Recursively generate mock data from JSON schema.
        
        SCALABLE: Works for any schema structure without hardcoding app names.
        Uses property names for context-aware mock generation for common patterns.
        
        Covered patterns:
        - Spreadsheets: values, valueRanges, rows, cells (Google Sheets, Excel, Smartsheet)
        - Databases: records, fields, entries (Airtable, Notion, Supabase)
        - Email/Messaging: messages, threads, attachments (Gmail, Outlook, Slack)
        - Files/Storage: files, items, entries (Google Drive, Dropbox, OneDrive)
        - Calendar: events, attendees (Google Calendar, Outlook Calendar)
        - CRM: contacts, deals, leads (Salesforce, HubSpot)
        - Generic: data, results, items, entries
        """
        # Calculate max_depth dynamically on first call
        if max_depth is None:
            max_depth = min(self._get_schema_max_depth(schema) + 2, 15)  # Add buffer, cap at 15
        
        if depth > max_depth:  # Dynamic depth limit
            return {}
        
        schema_type = schema.get('type', 'object')
        prop_lower = prop_name.lower()
        
        # =====================================================================
        # SPREADSHEET/TABLE PATTERNS (Google Sheets, Excel, Airtable, Smartsheet)
        # =====================================================================
        if prop_lower == 'values':
            # 2D array: headers + data rows (6 columns to cover most use cases)
            # Columns cover: identity, contact, category, numeric, text, date
            return [
                ['Name', 'Email', 'Category', 'Amount', 'Notes', 'Date'],
                ['John Smith', 'john@example.com', 'Research', '150.00', 'Sample notes 1', '2025-01-15'],
                ['Jane Doe', 'jane@example.com', 'Development', '200.00', 'Sample notes 2', '2025-02-15'],
                ['Bob Wilson', 'bob@example.com', 'Analysis', '175.00', 'Sample notes 3', '2025-03-15'],
            ]
        elif prop_lower == 'valueranges':
            # Google Sheets BATCH_GET response (6 columns to cover most use cases)
            return [{
                'range': 'Sheet1!A1:F4',
                'majorDimension': 'ROWS',
                'values': [
                    ['Name', 'Email', 'Category', 'Amount', 'Notes', 'Date'],
                    ['John Smith', 'john@example.com', 'Research', '150.00', 'Sample notes 1', '2025-01-15'],
                    ['Jane Doe', 'jane@example.com', 'Development', '200.00', 'Sample notes 2', '2025-02-15'],
                    ['Bob Wilson', 'bob@example.com', 'Analysis', '175.00', 'Sample notes 3', '2025-03-15'],
                ]
            }]
        elif prop_lower == 'rows':
            # Generic table rows
            return [
                {'id': 'row_1', 'Date': '2025-01-15', 'Amount': '150.00'},
                {'id': 'row_2', 'Date': '2025-02-15', 'Amount': '200.00'},
            ]
        elif prop_lower == 'cells':
            # Individual cells
            return [
                {'row': 1, 'column': 'A', 'value': 'Date'},
                {'row': 1, 'column': 'B', 'value': 'Amount'},
            ]
        
        # =====================================================================
        # DATABASE PATTERNS (Airtable, Notion, Supabase, Firebase)
        # =====================================================================
        elif prop_lower == 'records':
            # Airtable/Notion database records
            return [
                {'id': 'rec_001', 'fields': {'Name': 'Item 1', 'Status': 'Active', 'Amount': 150}},
                {'id': 'rec_002', 'fields': {'Name': 'Item 2', 'Status': 'Pending', 'Amount': 200}},
            ]
        elif prop_lower == 'fields':
            # Record fields (when accessed directly)
            return {'Name': 'Sample Record', 'Status': 'Active', 'Amount': 150, 'Date': '2025-01-15'}
        
        # =====================================================================
        # EMAIL/MESSAGING PATTERNS (Gmail, Outlook, Slack, Teams)
        # =====================================================================
        elif prop_lower == 'messages':
            return [
                {'id': 'msg_001', 'subject': 'Sample Email 1', 'from': 'sender@example.com', 'snippet': 'Email content preview...'},
                {'id': 'msg_002', 'subject': 'Sample Email 2', 'from': 'other@example.com', 'snippet': 'Another email preview...'},
            ]
        elif prop_lower == 'threads':
            return [
                {'id': 'thread_001', 'subject': 'Email Thread', 'messageCount': 3},
            ]
        elif prop_lower == 'attachments':
            return [
                {'id': 'att_001', 'filename': 'document.pdf', 'mimeType': 'application/pdf', 'size': 1024},
            ]
        elif prop_lower == 'channels':
            return [
                {'id': 'C001', 'name': 'general', 'is_private': False},
                {'id': 'C002', 'name': 'team-updates', 'is_private': False},
            ]
        
        # =====================================================================
        # FILE/STORAGE PATTERNS (Google Drive, Dropbox, OneDrive, Box)
        # =====================================================================
        elif prop_lower == 'files':
            return [
                {'id': 'file_001', 'name': 'Report.xlsx', 'mimeType': 'application/vnd.ms-excel', 'size': 2048},
                {'id': 'file_002', 'name': 'Presentation.pptx', 'mimeType': 'application/vnd.ms-powerpoint', 'size': 4096},
            ]
        elif prop_lower == 'folders':
            return [
                {'id': 'folder_001', 'name': 'Documents', 'itemCount': 15},
                {'id': 'folder_002', 'name': 'Projects', 'itemCount': 8},
            ]
        
        # =====================================================================
        # CALENDAR PATTERNS (Google Calendar, Outlook Calendar)
        # =====================================================================
        elif prop_lower == 'events':
            return [
                {'id': 'evt_001', 'summary': 'Team Meeting', 'start': '2025-01-15T10:00:00Z', 'end': '2025-01-15T11:00:00Z'},
                {'id': 'evt_002', 'summary': 'Project Review', 'start': '2025-01-16T14:00:00Z', 'end': '2025-01-16T15:00:00Z'},
            ]
        elif prop_lower == 'attendees':
            return [
                {'email': 'user1@example.com', 'responseStatus': 'accepted'},
                {'email': 'user2@example.com', 'responseStatus': 'tentative'},
            ]
        
        # =====================================================================
        # CRM PATTERNS (Salesforce, HubSpot, Pipedrive)
        # =====================================================================
        elif prop_lower == 'contacts':
            return [
                {'id': 'con_001', 'name': 'John Doe', 'email': 'john@example.com', 'phone': '+1234567890'},
                {'id': 'con_002', 'name': 'Jane Smith', 'email': 'jane@example.com', 'phone': '+0987654321'},
            ]
        elif prop_lower == 'deals' or prop_lower == 'opportunities':
            return [
                {'id': 'deal_001', 'name': 'Enterprise Deal', 'amount': 50000, 'stage': 'Negotiation'},
                {'id': 'deal_002', 'name': 'SMB Deal', 'amount': 5000, 'stage': 'Proposal'},
            ]
        elif prop_lower == 'leads':
            return [
                {'id': 'lead_001', 'name': 'New Lead', 'company': 'Acme Corp', 'status': 'New'},
            ]
        
        # =====================================================================
        # GENERIC PATTERNS (work across many APIs)
        # =====================================================================
        elif prop_lower == 'value':
            # Microsoft Graph API standard response format (Outlook, Teams, OneDrive, SharePoint)
            # Generic array of objects with common fields
            return [
                {'id': 'item_001', 'name': 'Sample Item 1'},
                {'id': 'item_002', 'name': 'Sample Item 2'},
            ]
        elif prop_lower == 'results':
            # Generic search/list results
            return [
                {'id': 'res_001', 'title': 'Result 1', 'score': 0.95},
                {'id': 'res_002', 'title': 'Result 2', 'score': 0.87},
            ]
        elif prop_lower == 'items':
            # Generic items list
            return [
                {'id': 'item_001', 'name': 'Item 1', 'type': 'default'},
                {'id': 'item_002', 'name': 'Item 2', 'type': 'default'},
            ]
        elif prop_lower == 'entries':
            # Generic entries
            return [
                {'id': 'entry_001', 'content': 'Entry content 1', 'created': '2025-01-15'},
                {'id': 'entry_002', 'content': 'Entry content 2', 'created': '2025-01-16'},
            ]
        elif prop_lower == 'data' and depth == 0:
            # Top-level data wrapper - don't override, let schema handle it
            pass
        
        # =====================================================================
        # FLIGHT/TRAVEL PATTERNS (Amadeus, Skyscanner, Composio flights)
        # =====================================================================
        elif prop_lower == 'flights':
            return [
                {'id': 'fl_001', 'airline': 'United', 'flight_number': 'UA123', 'departure': '2025-01-15T08:00:00Z', 'arrival': '2025-01-15T11:00:00Z', 'price': 350},
                {'id': 'fl_002', 'airline': 'Delta', 'flight_number': 'DL456', 'departure': '2025-01-15T10:00:00Z', 'arrival': '2025-01-15T13:00:00Z', 'price': 420},
            ]
        elif prop_lower == 'hotels':
            return [
                {'id': 'htl_001', 'name': 'Grand Hotel', 'rating': 4.5, 'price_per_night': 150},
                {'id': 'htl_002', 'name': 'City Inn', 'rating': 4.0, 'price_per_night': 95},
            ]
        
        # =====================================================================
        # DOCUMENT/CONTENT PATTERNS (Notion, Confluence, Google Docs)
        # =====================================================================
        elif prop_lower == 'blocks':
            return [
                {'id': 'blk_001', 'type': 'paragraph', 'text': 'Sample paragraph content'},
                {'id': 'blk_002', 'type': 'heading', 'text': 'Sample Heading'},
            ]
        elif prop_lower == 'pages':
            return [
                {'id': 'page_001', 'title': 'Project Overview', 'url': 'https://example.com/page1'},
                {'id': 'page_002', 'title': 'Meeting Notes', 'url': 'https://example.com/page2'},
            ]
        
        if schema_type == 'object':
            properties = schema.get('properties', {})
            
            # SCALABLE FIX: If schema says 'object' but has no properties
            # Schema has `additionalProperties: true` but no defined `properties`
            # This means: "it's an object, but structure is unknown/dynamic"
            if not properties:  # Empty object schema
                # Return an empty dict - this is valid per the schema and scalable for ANY API
                # The LLM will see it's empty and either:
                # 1. Realize there's no data and handle gracefully
                # 2. Get a KeyError when trying to access fields, then retry with a fix
                # This avoids returning strings that cause TypeError when accessed as dicts
                print(f"[COMPOSIO_PLUGIN] ‚ö†Ô∏è Empty object schema for '{prop_name}' - returning empty dict")
                return {}
            
            mock_obj = {}
            for pname, prop_schema in list(properties.items())[:15]:  # Limit to 15 props for completeness
                mock_obj[pname] = self._generate_mock_from_schema(prop_schema, depth + 1, pname, max_depth)
            
            return mock_obj
            
        elif schema_type == 'array':
            items_schema = schema.get('items', {})
            return [self._generate_mock_from_schema(items_schema, depth + 1, prop_name, max_depth)]
            
        elif schema_type == 'string':
            # Check for format hints first
            format_hint = schema.get('format', '')
            if 'email' in format_hint:
                return 'example@domain.com'
            elif 'date' in format_hint:
                return '2024-01-01'
            elif 'uri' in format_hint or 'url' in format_hint:
                return 'https://example.com'
            
            # DYNAMIC: Generate context-aware values based on property name
            # Works for ANY API - spreadsheetId, documentId, projectId, channelId, etc.
            if prop_lower.endswith('id') or prop_lower.endswith('_id'):
                # Extract the entity name: spreadsheetId -> spreadsheet, channel_id -> channel
                entity = prop_lower.replace('_id', '').replace('id', '').strip('_')
                if entity:
                    return f'{entity}_abc123xyz'  # e.g., 'spreadsheet_abc123xyz'
                return 'id_abc123xyz'
            elif prop_lower == 'name' or prop_lower.endswith('name'):
                return 'Sample Name'
            elif prop_lower == 'title':
                return 'Sample Title'
            elif prop_lower == 'description':
                return 'Sample description text'
            elif 'email' in prop_lower:
                return 'example@domain.com'
            elif 'url' in prop_lower or 'link' in prop_lower:
                return 'https://example.com/resource'
            elif 'path' in prop_lower:
                return '/sample/path'
            elif 'type' in prop_lower or 'kind' in prop_lower:
                return 'default_type'
            elif 'status' in prop_lower or 'state' in prop_lower:
                return 'active'
            else:
                # SCALABLE FIX: Use property-based value that won't trigger placeholder detection
                # Instead of 'sample_value' (triggers 'sample_' pattern), generate a unique value
                # This works for ALL 800+ tools without hardcoding specific fields
                return f'{prop_lower}_abc123xyz' if prop_lower else 'value_abc123xyz'
                
        elif schema_type == 'integer':
            return 1
            
        elif schema_type == 'number':
            return 1.0
            
        elif schema_type == 'boolean':
            return True
            
        else:
            return 'value'
    
    def _get_service(self):
        """Get or create ComposioService instance (lazy initialization)."""
        if self._composio_service is None:
            try:
                # Add Django app path to sys.path if needed
                django_app_path = os.path.join(
                    os.path.dirname(__file__), 
                    '..', '..', '..'  # TaskWeaver/project/plugins -> xtrac-app-api
                )
                abs_path = os.path.abspath(django_app_path)
                if abs_path not in sys.path:
                    sys.path.insert(0, abs_path)
                
                # Setup Django if not already
                import django
                os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'config.settings')
                if not django.apps.apps.ready:
                    django.setup()
                
                # Import and initialize ComposioService
                from apps.integrations.services.composio_service import ComposioService
                self._composio_service = ComposioService()
                logger.info("[COMPOSIO_PLUGIN] ComposioService initialized")
                
            except ImportError as e:
                logger.error(f"[COMPOSIO_PLUGIN] Failed to import ComposioService: {e}")
                raise RuntimeError(
                    "ComposioService not available. "
                    "Make sure Django app is properly configured."
                )
            except Exception as e:
                logger.error(f"[COMPOSIO_PLUGIN] Failed to initialize: {e}")
                raise
        
        return self._composio_service
    
    def _format_rich_description(self, data: Any, action_name: str) -> str:
        """
        Generate a rich, human-readable description of the action result.
        
        This uses the content_preparer utility (SINGLE SOURCE OF TRUTH) to format
        complex data into beautiful, readable output suitable for email bodies,
        messages, and other content parameters.
        
        Args:
            data: Action result data
            action_name: Name of the executed action
            
        Returns:
            Human-readable HTML description
        """
        try:
            # Import content_preparer (SINGLE SOURCE OF TRUTH)
            from apps.py_workflows.execution.utils.content_preparer import prepare_content
            
            # Use HTML formatting for rich output
            description = prepare_content(
                data=data,
                param_name=action_name,
                use_html=True,
                logger_instance=logger
            )
            
            logger.info(f"[COMPOSIO_PLUGIN] Generated rich description ({len(description)} chars)")
            return description
            
        except ImportError:
            # Fallback if content_preparer not available
            logger.warning("[COMPOSIO_PLUGIN] content_preparer not available, using basic description")
            return self._basic_description(data, action_name)
        except Exception as e:
            logger.warning(f"[COMPOSIO_PLUGIN] Rich formatting failed: {e}, using basic")
            return self._basic_description(data, action_name)
    
    def _basic_description(self, data: Any, action_name: str) -> str:
        """Basic fallback description when rich formatting is unavailable."""
        description = f"Successfully executed {action_name}. "
        
        if isinstance(data, dict):
            keys = list(data.keys())[:5]
            description += f"Result contains: {', '.join(keys)}"
        elif isinstance(data, list):
            description += f"Result contains {len(data)} items."
        else:
            description += f"Result type: {type(data).__name__}"
        
        return description
    
    def __call__(
        self, 
        action_name: str, 
        params: Optional[Dict[str, Any]] = None,
        entity_id: Optional[str] = None
    ) -> Tuple[Dict[str, Any], str]:
        """
        Execute a Composio action.
        
        Args:
            action_name: Composio action ID (e.g., "GOOGLESHEETS_BATCH_GET", "GMAIL_SEND_EMAIL")
            params: Action parameters as a dictionary
            entity_id: User's entity ID for authentication (optional, uses config if not provided)
            
        Returns:
            Tuple of (result_dict, description_string)
            - result_dict: Action result data or error info
            - description_string: Human-readable description of the result
            
        Examples:
            # Get spreadsheet data
            result, desc = composio_action(
                action_name="GOOGLESHEETS_SPREADSHEETS_VALUES_BATCH_GET",
                params={"spreadsheetId": "1abc...", "ranges": ["Sheet1!A1:B10"]}
            )
            
            # Send email
            result, desc = composio_action(
                action_name="GMAIL_SEND_EMAIL",
                params={"to": "user@example.com", "subject": "Hello", "body": "Message"}
            )
            
            # Search for spreadsheet by name
            result, desc = composio_action(
                action_name="GOOGLESHEETS_FIND_SPREADSHEET",
                params={"name": "My Spreadsheet"}
            )
        """
        params = params or {}
        original_action = action_name  # Keep original for logging
        
        # =====================================================================
        # SIMULATION MODE CHECK
        # =====================================================================
        # If running in Docker CES (TaskWeaver's code execution sandbox),
        # Django services are NOT available. Return mock response so TaskWeaver
        # continues generating code for ALL plan steps.
        #
        # Actual execution happens later via langgraph_adapter with real APIs.
        # =====================================================================
        if self._is_simulation_mode():
            logger.info(f"[COMPOSIO_PLUGIN] SIMULATION MODE: {action_name}")
            
            # =====================================================================
            # TASKWEAVER PATTERN: Let the LLM learn from natural API feedback
            # =====================================================================
            # Instead of pre-validating parameters and blocking execution,
            # let the mock data be generated and returned.
            # 
            # If parameters are semantically wrong (e.g., "New York" for departure_id),
            # the mock data structure will be returned, and the LLM will see from the
            # description whether it needs to adjust its approach.
            #
            # This follows TaskWeaver's core philosophy (see sql_pull_data.py, klarna_search.py):
            # 1. Plugins are simple executors - they don't try to outsmart the LLM
            # 2. They return (data, description) 
            # 3. The LLM learns from the feedback loop
            #
            # The LLM will self-correct through retries when it sees unexpected results.
            # =====================================================================
            # (Placeholder detection removed - following TaskWeaver's established pattern)
            
            return self._get_mock_response(action_name, params)
        
        # =====================================================================
        # ACTION RESOLUTION (sql_pull_data pattern)
        # =====================================================================
        # TaskWeaver's LLM may generate conceptual names like GMAIL_GET_LAST_EMAILS.
        # Resolve to actual DB action using semantic search.
        # =====================================================================
        action_name = self._resolve_action(action_name)
        
        if action_name != original_action:
            logger.info(f"[COMPOSIO_PLUGIN] Action resolved: {original_action} -> {action_name}")
        
        # =====================================================================
        # PARAMETER NAME RESOLUTION (sql_pull_data pattern)
        # =====================================================================
        # TaskWeaver's LLM may use approximate param names like 'name' instead of 'title'.
        # Resolve to actual schema params using semantic matching.
        # =====================================================================
        original_params = params.copy()
        params = self._resolve_params(action_name, params)
        
        if params != original_params:
            changed = {k: v for k, v in params.items() if k not in original_params or original_params.get(k) != v}
            logger.info(f"[COMPOSIO_PLUGIN] Param names resolved: {list(original_params.keys())} -> {list(params.keys())}")
        
        # =====================================================================
        # PARAMETER VALUE RESOLUTION (sql_pull_data pattern)
        # =====================================================================
        # If a param value looks like a human name but schema expects an ID,
        # automatically call a SEARCH/FIND action to resolve it.
        # Uses parameter_examples from DB to detect format mismatch.
        # =====================================================================
        params_before_value_resolution = params.copy()
        params = self._resolve_param_values(action_name, params, entity_id)
        
        if params != params_before_value_resolution:
            for k, v in params.items():
                if params_before_value_resolution.get(k) != v:
                    logger.info(f"[COMPOSIO_PLUGIN] Param value resolved: {k}='{params_before_value_resolution.get(k)}' -> '{v}'")
        
        try:
            service = self._get_service()
            
            # Get entity_id with priority: parameter > session_var > config > default
            # Session var is set by langgraph_adapter during execution
            if not entity_id:
                entity_id = self.ctx.get_session_var("_composio_entity_id", None) or \
                            self.config.get('entity_id', 'default')
            
            logger.info(f"[COMPOSIO_PLUGIN] Executing: {action_name}")
            logger.info(f"[COMPOSIO_PLUGIN] Params: {params}")
            logger.info(f"[COMPOSIO_PLUGIN] Entity: {entity_id}")
            
            # Get connected account for this action
            app_name = action_name.split('_')[0].lower()
            connected_account_id = None
            
            if not service.is_no_auth_app(app_name):
                # Try to get connection for this app
                try:
                    connections = service.get_user_connections(entity_id)
                    for conn in connections:
                        if conn.get('app_name', '').lower() == app_name:
                            if conn.get('status', '').upper() == 'ACTIVE':
                                connected_account_id = conn.get('id')
                                logger.info(f"[COMPOSIO_PLUGIN] Using connection: {connected_account_id}")
                                break
                except Exception as conn_err:
                    logger.warning(f"[COMPOSIO_PLUGIN] Could not get connections: {conn_err}")
            
            # Execute the action
            result = service.execute_action(
                action_name=action_name,
                params=params,
                entity_id=entity_id,
                connected_account_id=connected_account_id
            )
            
            if result.get('success') or result.get('successfull'):
                data = result.get('data', result)
                
                # RICH DESCRIPTION: Use content_preparer for human-readable output
                # This is the SINGLE SOURCE OF TRUTH for content formatting
                description = self._format_rich_description(data, action_name)
                
                # ‚úÖ CRITICAL: Print description so LLM can see it in execution logs!
                print(f"\n{description}\n")
                
                logger.info(f"[COMPOSIO_PLUGIN] Action succeeded: {action_name}")
                return data, description
            else:
                # =====================================================================
                # CRITICAL FIX (arch-25): RAISE EXCEPTION on API failure!
                # =====================================================================
                # Previously: We returned error dict ‚Üí Python "succeeded" ‚Üí no retry
                # Now: We RAISE an exception ‚Üí Python fails ‚Üí TaskWeaver retries!
                #
                # This enables TaskWeaver's self-correction loop to fix issues like:
                # - "Missing required field: valueInputOption"
                # - "is_html must be true for HTML content"
                # =====================================================================
                error_msg = result.get('error', 'Unknown error')
                logger.error(f"[COMPOSIO_PLUGIN] API FAILURE (will trigger retry): {error_msg}")
                
                # Raise exception with detailed message for LLM to understand
                raise RuntimeError(
                    f"Composio API error for {action_name}: {error_msg}\n"
                    f"Parameters provided: {list(params.keys())}\n"
                    f"Please fix the parameters and retry."
                )
                
        except Exception as e:
            error_msg = str(e)
            description = f"Exception executing {action_name}: {error_msg}"
            logger.error(f"[COMPOSIO_PLUGIN] Exception: {e}", exc_info=True)
            
            return {
                'error': True,
                'error_message': error_msg,
                'action': action_name
            }, description


@test_plugin(name="test_composio_action", description="Test Composio action plugin")
def test_call(api_call):
    """Test the Composio action plugin with a no-auth action."""
    # Test with a simple search (no auth required)
    result, description = api_call(
        action_name="COMPOSIO_SEARCH_TOOLS",
        params={"query": "email"}
    )
    
    # Should return something (even if error due to missing config)
    assert result is not None
    assert description is not None
